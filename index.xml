<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hugo Cactus Theme</title>
    <link>https://lzy175.github.io/</link>
    <description>Recent content on Hugo Cactus Theme</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Mar 2022 16:49:17 +0800</lastBuildDate><atom:link href="https://lzy175.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>有关单例模式和代理模式的学习</title>
      <link>https://lzy175.github.io/posts/%E6%9C%89%E5%85%B3%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%92%8C%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Fri, 18 Mar 2022 16:49:17 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%9C%89%E5%85%B3%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%92%8C%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AD%A6%E4%B9%A0/</guid>
      <description>单例模式 一个类只有一个实例，精髓在于构造方法私有化。
饿汉式单例：
public class study{ private static study s = new study(); private study(){ } public static study get(){ return s; } } 饱汉式单例：
public class study{ private static study s; private study(){ } private synchronized static study get(){ if(s == null){ return new study(); } return s; } } 双重检验锁方式实现单例模式：
为了解决同步和性能问题：
public class Student{ private static volatile Student student; private Student(){} public static Student get(){ if(student == null){ synchronized(Student.</description>
    </item>
    
    <item>
      <title>JDBC对双亲委派模型的破坏分析</title>
      <link>https://lzy175.github.io/posts/jdbc%E5%AF%B9%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A0%B4%E5%9D%8F%E5%88%86%E6%9E%90/</link>
      <pubDate>Tue, 15 Mar 2022 10:10:16 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/jdbc%E5%AF%B9%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A0%B4%E5%9D%8F%E5%88%86%E6%9E%90/</guid>
      <description>类加载器 通过类的全限定名获取类的二进制文件流。是对类进行解析的重要工具。
类加载器有三种，依次是启动类加载器（bootstrapClassLoader），扩展类加载器，和应用程序类加载器（AppclassLoader).
启动类加载器负责加载java的核心类库，比如rt.jar这种；
扩展类加载器，一般是在扩展目录下加载类库，\lib\ext目录或者java.ext.dirs系统变量指定的路径中的所有目录；
应用程序类加载器负责加载环境变量classPath或者java.class.path指定路径下的类库。是应用程序中默认的类加载器。
双亲委派的具体内容就是：
一个类加载器在加载某一个类的时候，首先委派给他的父类加载器去加载，依次递归，所以所有的加载请求其实都会汇聚到启动类加载器里面，如果父类加载器可以完成这个类的加载，那么就成功返回，如果加载不了，再由子类加载器进行加载。
代码角度分析类加载的过程如下：
public Class&amp;lt;?&amp;gt; loadClass(String name) throws ClassNotFoundException { return loadClass(name, false); } protected synchronized Class&amp;lt;?&amp;gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) { //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try { if (parent != null) { //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); } else { // 递归终止条件 // 由于启动类加载器无法被Java程序直接引用，因此默认用 null 替代 // parent == null就意味着由启动类加载器尝试加载该类， // 即通过调用 native方法 findBootstrapClass0(String name)加载 c = findBootstrapClass0(name); } } catch (ClassNotFoundException e) { // 如果父类加载器不能完成加载请求时，再调用自身的findClass方法进行类加载，若加载成功，findClass方法返回的是defineClass方法的返回值 // 注意，若自身也加载不了，会产生ClassNotFoundException异常并向上抛出 c = findClass(name); } } //是否需要连接该类 if (resolve) { resolveClass(c); } return c; } 双亲委派的意义：</description>
    </item>
    
    <item>
      <title>Spring中bean生命周期源码的了解</title>
      <link>https://lzy175.github.io/posts/spring%E4%B8%ADbean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%BA%90%E7%A0%81%E7%9A%84%E4%BA%86%E8%A7%A3/</link>
      <pubDate>Sat, 15 Jan 2022 16:44:29 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/spring%E4%B8%ADbean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%BA%90%E7%A0%81%E7%9A%84%E4%BA%86%E8%A7%A3/</guid>
      <description>Spring中bean的生命周期
1、实例化
2、填充属性
3、执行aware接口实现的方法
aware接口存在的意义：方便通过Spring中的bean对象来获取对应容器中的相关属性值。
4、BeanPostProcessor.before (bean扩展)
5、init-method方法
6、BeanPostProcessor.after（bean扩展）
得到完整对象
7、销毁流程
debug流程，以xml配置文件方式进行debug：
@SpringBootApplication //对应到mappers包 @MapperScan(&amp;#34;com.example.seckill.db.mappers&amp;#34;) @ComponentScan(basePackages = {&amp;#34;com.example&amp;#34;}) public class SckillApplication { public static void main(String[] args) { SpringApplication.run(SckillApplication.class, args); AnnotationConfigApplicationContext annotationConfigApplicationContext; //配置文件 ClassPathXmlApplicationContext classPathXmlApplicationContext; } } public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent) throws BeansException { //执行父类的构造方法 super(parent); //设置配置路径 this.setConfigLocations(configLocations); //refrash 超级重要 if (refresh) { this.refresh(); } } //AbstractApplicationContext类 public void refresh() throws BeansException, IllegalStateException { synchronized(this.startupShutdownMonitor) { StartupStep contextRefresh = this.</description>
    </item>
    
    <item>
      <title>AQS源码初探</title>
      <link>https://lzy175.github.io/posts/aqs%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2/</link>
      <pubDate>Sun, 12 Sep 2021 11:45:13 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/aqs%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2/</guid>
      <description>AQS消息同步队列是java中一个重要的底层数据结构，熟知的reeetrantlock、CountdownLatch和CyclicBarrier的底层都是AQS。AQS的数据结构内部有一个共享资源变量state：这是一个volatile标志的int整形数，支持在多线程下的可见性，根据子类取不同的意义，比如：reetrantlock底层的state如果是1，表示该线程已经获取到该锁；从1升到2，表示加了可重入锁；如果state是0，表示已经释放锁。
CountdownLatch底层的state表示需要countdown的次数。
跟随着state的还有一个FIFO等待队列，是一个双向链表，一个节点中表示一个线程，有前节点，后节点，多线程竞争state被阻塞会进入到此队列，实现方式为CAS。当等待队列的一个节点拿到了state的值，就相当于节点拿到了锁。
以下源码只涉及到独占式获取锁：
//进入到ReentrantLock的内部类NonfairSync 中的lock()方法 // 使用 CAS 来获取 state 资源，如果成功设置 1，代表 state 资源获取锁成功， // 此时记录下当前占用 state 的线程 setExclusiveOwnerThread(Thread.currentThread()); // 如果 CAS 设置 state 为 1 失败（代表获取锁失败），则执行 acquire(1) 方法，再次尝试 final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } 使用acquire（）方法获取锁，这是个核心方法：
//这里是获取锁的acquire(1)方法 //首先 调用 tryAcquire 尝试着获取 state，如果成功，则跳过后面的步骤。如果失败，则执行 //acquireQueued 将线程加入 CLH 等待队列中 public final void acquire(int arg) { if (!tryAcquire(arg) &amp;amp;&amp;amp; //在CLH等待队列中的线程处于一种”自旋状态“，尝试让该线程重新获取锁 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } tryAcquire（）方法并没有在AQS中直接实现，而是采用模板方法的设计模式，交给子类去实现，其中公平锁的实现如下：
protected final boolean tryAcquire(int acquires) { // 当前线程 final Thread current = Thread.</description>
    </item>
    
    <item>
      <title>Redis实现分布式锁与其他实现方案</title>
      <link>https://lzy175.github.io/posts/redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E4%B8%8E%E5%85%B6%E4%BB%96%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88/</link>
      <pubDate>Wed, 25 Aug 2021 17:24:33 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E4%B8%8E%E5%85%B6%E4%BB%96%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88/</guid>
      <description>分布式系统确实能带来性能和效率上的提升，目前单机的局限越来越大，大多数互联网系统都是分布式部署的，但为此，我们就需要多解决一个分布式环境下，数据一致性的问题，这里有个很重要的CAP理论。
CAP理论是在设计分布式系统的过程中，处理数据一致性问题时必须考虑的理论，而CAP理论说的就是：一个分布式系统，不可能同时做到这三点C、A、P。
CAP即：
Consistency（一致性） Availability（可用性） Partition tolerance（分区容忍性） 翻译一下就是： ①**一致性：**对于客户端的每次读操作，要么读到的是最新的数据，要么读取失败。换句话说，一致性是站在分布式系统的角度，对访问本系统的客户端的一种承诺：要么我给您返回一个错误，要么我给你返回绝对一致的最新数据，不难看出，其强调的是数据正确。
②**可用性：**任何客户端的请求都能得到响应数据，不会出现响应错误。换句话说，可用性是站在分布式系统的角度，对访问本系统的客户的另一种承诺：我一定会给您返回数据，不会给你返回错误，但不保证数据最新，强调的是不出错。
③**分区容忍性：**由于分布式系统通过网络进行通信，网络是不可靠的。当任意数量的消息丢失或延迟到达时，系统仍会继续提供服务，不会挂掉。换句话说，分区容忍性是站在分布式系统的角度，对访问本系统的客户端的再一种承诺：我会一直运行，不管我的内部出现何种数据同步问题，强调的是不挂掉。
谈回分布式，当某个资源在多系统之间，具有共享性的时候，为了保证大家访问这个资源数据是一致的，那么就必须要求在同一时刻只能被一个客户端处理，不能并发的执行，否者就会出现同一时刻有人写有人读，大家访问到的数据就不一致了。
在单机时代，虽然不需要分布式锁，但也面临过类似的问题，只不过在单机的情况下，如果有多个线程要同时访问某个共享资源的时候，我们可以采用线程间加锁的机制，即当某个线程获取到这个资源后，就立即对这个资源进行加锁，当使用完资源之后，再解锁，其它线程就可以接着使用了。例如，在JAVA中，甚至专门提供了一些处理锁机制的一些API（synchronize/Lock等）。
但是到了分布式系统的时代，这种线程之间的锁机制，就没作用了，系统可能会有多份并且部署在不同的机器上，这些资源已经不是在线程之间共享了，而是属于进程之间共享的资源。
因此，为了解决这个问题，就必须引入「分布式锁」。
分布式锁，是指在分布式的部署环境下，通过锁机制来让多客户端互斥的对共享资源进行访问。
分布式锁要要求：
排他性：在同一时间只会有一个客户端能获取到锁，其它客户端无法同时获取； 避免死锁：这把锁在一段有限的时间之后，一定会被释放（正常释放或异常释放）； 高可用：获取或释放锁的机制必须高可用且性能佳。 目前主流的有三种，从实现的复杂度上来看，从上往下难度依次增加：
基于数据库实现 基于Redis实现 基于ZooKeeper实现 接下来着重介绍下基于redis的分布式锁实现：
使用SETNX实现
SETNX的使用方式为：SETNX key value，只在键key不存在的情况下，将键key的值设置为value，若键key存在，则SETNX不做任何动作。
boolean result = jedis.setnx(&amp;#34;lock-key&amp;#34;,true)== 1L; if (result) { try { // do something } finally { jedis.del(&amp;#34;lock-key&amp;#34;); } } 这种方案有一个致命问题，就是某个线程在获取锁之后由于某些异常因素（比如宕机）而不能正常的执行解锁操作，那么这个锁就永远释放不掉了。
为此，我们可以为这个锁加上一个超时时间
执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value
执行 SET key value PX milliseconds 的效果等同于执行 PSETEX key milliseconds value</description>
    </item>
    
    <item>
      <title>对于redis实际操作的学习</title>
      <link>https://lzy175.github.io/posts/%E5%AF%B9%E4%BA%8Eredis%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Thu, 12 Aug 2021 16:56:09 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E5%AF%B9%E4%BA%8Eredis%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C%E7%9A%84%E5%AD%A6%E4%B9%A0/</guid>
      <description>本篇博客仅记录笔者操作过程中使用到的命令，对于理论知识比如redis五大数据类型的底层结构，redis单线程相关知识，redis持久化等等知识点不做详解，有兴趣的读者可自行百度或者查看笔者的其他相关博客。
redis存储的是：key,value格式的数据，其中key都是字符串，value有5种不同的数据结构：
String类型 string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value； string类型是二进制安全的。意思是redis的string可以包含任何数据。如jpg图片或者序列化的对象 ； string类型是Redis最基本的数据类型，一个redis中字符串value最多可以是512M；
常用命令操作：
SET key value（存储：将字符串值 value 关联到 key） GET key（获取：返回与键 key 相关联的字符串值） DEL key（删除：删除给定的 key ） APPEND key value（ APPEND 命令将把 value 追加到键 key 现有值的末尾，没有 key 就自动添加） STRLEN key（返回键 key 储存的字符串值的长度） 哈希类型 hash ： (map格式) redis的hash 是一个键值对集合； redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象； 类似Java里面的Map&amp;lt;String,Object&amp;gt;； 常用命令操作：
HSET key field value（存储：将哈希表 hash 中域 field 的值设置为 value） HGET key field（获取：获取指定的field对应的值） HDEL key field（删除：删除哈希表 key 中的一个或多个指定域，不存在的域将被忽略） HMSET key field value [field value …]（同时将多个 field-value (域-值)对设置到哈希表 key 中） HMGET key field [field …]（返回哈希表 key 中，一个或多个给定域的值） HGETALL key（返回哈希表 key 中，所有的域和值） 列表类型 list ：（linkedlist格式。支持重复元素） redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。它的底层实际是个链表。 常用命令操作：</description>
    </item>
    
    <item>
      <title>手写RPC---网络传输</title>
      <link>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%B8%83/</link>
      <pubDate>Tue, 10 Aug 2021 17:42:29 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%B8%83/</guid>
      <description>网络传输部分使用netty，这部分就是将先前的代码整合，作为handler，处理完毕后在网络中传输。
服务端接收和发送：
package com.rrtv.rpc.server.transport; import java.net.InetAddress; /** * @Date: 2021/7/24 22:22 */ @Slf4j public class NettyRpcServer implements RpcServer { //开启服务 @Override public void start(int port) { //监听端口 EventLoopGroup boss = new NioEventLoopGroup(); //这个是用来处理工作的 EventLoopGroup worker = new NioEventLoopGroup(); try { String serverAddress = InetAddress.getLocalHost().getHostAddress(); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(boss, worker) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { socketChannel.pipeline() // 协议编码 .addLast(new RpcEncoder()) // 协议解码 .</description>
    </item>
    
    <item>
      <title>手写RPC---负载均衡</title>
      <link>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E5%85%AD/</link>
      <pubDate>Fri, 30 Jul 2021 17:42:29 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E5%85%AD/</guid>
      <description>项目实现了两个负载均衡算法，随机负载均衡和轮询负载均衡
使用的步骤：
首先，消费的实现已经创建了动态代理实现，所以真的调用方法在动态代理的invoke里面，
invoke的第一步就调用了discoverService.discovery方法，目的是根据服务名称和版本号找到zk中哪些服务端有这个服务。代码如下：
package com.rrtv.rpc.core.discovery; /** * @Classname ZookeeperRegistryService * @Description * @Date 2021/7/15 14:35 */ @Slf4j public class ZookeeperDiscoveryService implements DiscoveryService { public static final int BASE_SLEEP_TIME_MS = 1000; public static final int MAX_RETRIES = 3; public static final String ZK_BASE_PATH = &amp;#34;/demo_rpc&amp;#34;; private ServiceDiscovery&amp;lt;ServiceInfo&amp;gt; serviceDiscovery; private LoadBalance loadBalance; //构造方法，输入为负载均衡策略 和zk的地址 public ZookeeperDiscoveryService(String registryAddr, LoadBalance loadBalance) { this.loadBalance = loadBalance; try { //zookeeper的东西，使用静态工程方法创建客户端，registryAddr是服务器列表 CuratorFramework client = CuratorFrameworkFactory.newClient(registryAddr, new ExponentialBackoffRetry(BASE_SLEEP_TIME_MS, MAX_RETRIES)); //zk客户端启动 client.</description>
    </item>
    
    <item>
      <title>手写RPC---服务的发布与消费</title>
      <link>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%BA%94/</link>
      <pubDate>Wed, 28 Jul 2021 17:15:26 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%BA%94/</guid>
      <description>发布服务 HelloWordServiceImpl方法：
@RpcService(interfaceType = HelloWordService.class, version = &amp;#34;1.0&amp;#34;) public class HelloWordServiceImpl implements HelloWordService { @Override public String sayHello(String name) { return String.format(&amp;#34;您好：%s, rpc 调用成功&amp;#34;, name); } } 服务提供者需要在暴露的服务上增加注解@RpcService，这个自定义注解基于@Service，是一个复合注解，在@RpcService注解中指明服务接口和服务版本，发布服务到ZK上，会根据这两个元数据注册。
@RpcService
@Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Service public @interface RpcService { /** * 暴露服务接口类型 * @return */ Class&amp;lt;?&amp;gt; interfaceType() default Object.class; /** * 服务版本 * @return */ String version() default &amp;#34;1.0&amp;#34;; } rpc-server-spring-boot-starter是服务提供者模块，RpcServerProvider实现了BeanPostProcessor接口（Spring的一个重要扩展点）和CommandLineRunner接口。
BeanPostProcessor接口包含了两个方法：
postProcessBeforeInitialization（）方法：在bean实例化、属性注入后，初始化前调用。
postProcessAfterInitialization（）方法：在bean实例化、属性注入，初始化都完成后调用。
CommandLineRunner接口只包含一个方法：
run（）方法：项目启动之后，立即执行的操作
package com.rrtv.rpc.server; import com.rrtv.rpc.core.common.ServiceInfo; import com.rrtv.rpc.core.common.ServiceUtil; import com.</description>
    </item>
    
    <item>
      <title>手写RPC---序列化和反序列化</title>
      <link>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E5%9B%9B/</link>
      <pubDate>Sun, 25 Jul 2021 16:45:19 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E5%9B%9B/</guid>
      <description>在encode的代码里，记录真正消息的body时，是将messageProtocol中的body（就是RpcRequest ）先序列化，然后再写入的。要用到序列化技术，注意只有实现了Serializable接口的类才能序列化。
项目目前实现了Hession序列化和Json序列化。具体的序列化方式在消息头部声明。
RpcSerialization 序列化接口：
package com.rrtv.rpc.core.serialization; import java.io.IOException; /** * @Author: lzy * @Date: 2021/7/14 13:36 */ public interface RpcSerialization { &amp;lt;T&amp;gt; byte[] serialize(T obj) throws IOException; &amp;lt;T&amp;gt; T deserialize(byte[] data, Class&amp;lt;T&amp;gt; clz) throws IOException; } json序列化（一下代码参考互联网，笔者对序列化技术的实际操作有点弱）：
package com.rrtv.rpc.core.serialization; import com.fasterxml.jackson.annotation.JsonInclude; import com.fasterxml.jackson.databind.DeserializationFeature; import com.fasterxml.jackson.databind.ObjectMapper; import java.io.IOException; import java.nio.charset.StandardCharsets; import java.text.SimpleDateFormat; import java.util.Arrays; /** * @Author: lzy * @Date: 2021/7/14 13:36 */ public class JsonSerialization implements RpcSerialization { private static final ObjectMapper MAPPER; static { MAPPER = generateMapper(JsonInclude.</description>
    </item>
    
    <item>
      <title>手写RPC---自定义的消息协议和编解码方式</title>
      <link>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%B8%89/</link>
      <pubDate>Fri, 23 Jul 2021 15:37:50 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%B8%89/</guid>
      <description>自定义协议这部分很灵活其实，笔者在网上看到了很多的自定义消息协议，根据目的和应用场景的不同出入也很大，笔者这里参考了网上的一些写法，又加了自己认为比较有必要的一些东西，仅供参考，如果读者有更好的想法或者意见，欢迎讨论，技术是在讨论中不断进步的。
MessageProtocol，包括了两部分，消息头和消息体：
package com.rrtv.rpc.core.protocol; import lombok.Data; import java.io.Serializable; /** * @Classname MessageProtocol * @Description 消息协议 * @Date 2021/7/13 15:33 * @Created by lzy */ @Data public class MessageProtocol&amp;lt;T&amp;gt; implements Serializable { /** * 消息头 */ private MessageHeader header; /** * 消息体，消息体分为两种，reponse和request，这里以泛型表示 */ private T body; } request消息体：
package com.rrtv.rpc.core.common; import lombok.Data; import java.io.Serializable; /** * @Author: lzy * @Date: 2021/7/13 22:55 */ @Data public class RpcRequest implements Serializable { /** * 请求的服务名 + 版本 */ private String serviceName; /** * 请求调用的方法 */ private String method; /** * 参数类型 */ private Class&amp;lt;?</description>
    </item>
    
    <item>
      <title>手写RPC---整体框架的构建</title>
      <link>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%BA%8C/</link>
      <pubDate>Tue, 20 Jul 2021 15:10:38 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%BA%8C/</guid>
      <description>RPC的基础功能之一就是对服务端相应功能的注册与发现，在本项目中使用zookeeper作为注册中心，目前未提供切换以及用户自定义注册中心的功能。
IO通信框架选择NEtty作为底层的通信框架，没有选择java自己的NIO接口（一是接口众多，实现起来不够简便；二是那个epoll空轮询bug），不支持用户自定义的通信框架。
消息协议，本实现使用自定义的消息协议，后面会具体说明。
项目总体结构： consumer模块：服务消费者；
provider模块：服务提供者；
provider-api模块：服务提供者暴露的服务API；
rpc-client-spring-boot-starter模块：客户端的starter，封装客户端发起的请求过程（jdk动态代理，网络通信）；
rpc-core模块：RPC的核心依赖，负载均衡策略，消息协议，协议编解码，序列化，请求响应实体、服务注册发现；
rpc-server-spring-boot-starter模块：服务端端的starter，负责发布RPC服务，接收和处理RPC请求，反射调用服务端。
这里的starter意图是尽量减少相关配置，有兴趣的读者可以直接去了解一下Spring boot的自动装配，这个starter的原理是spring boot对spring 框架的重要简化手段之一。大体上讲就是：spring boot启动时，会自动加载maven依赖MATE-INF文件夹下面的spring.factories文件，只要在该文件中指向一个配置文件，只要在该文件中配置一些需要的bean，依赖此模块项目会自动拿到这些bean ，并配置到自己的spring容器中。
org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.rrtv.rpc.client.config.RpcClientAutoConfiguration </description>
    </item>
    
    <item>
      <title>手写RPC---RPC的初步认识</title>
      <link>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%B8%80/</link>
      <pubDate>Sun, 18 Jul 2021 17:42:29 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E6%89%8B%E5%86%99rpc%E4%B8%80/</guid>
      <description>rpc是指远程过程调用，关注的一般是远程方法调用，微服务会将一个项目服务分成几个规模较小的服务，把这些服务分别部署在不同的服务器中，来达到一种解耦合提高效率的目的，但是不同的服务之间一定会有交互，通过这种交互来完成系统的整体性，这种交互过程有时候就是一个服务得区调用另一个服务的方法，就是在一台服务器上，调用另一台服务器的某个方法，RPC就是这样一种框架，通过RPC可以在本地计算机上调用远程计算机上某个服务的方法。
RPC通常包括两类协议：1、传输协议和 序列化协议
传输协议：
著名的grpc，底层使用的就是http2协议；dubbo一类的是使用自定义报文的tcp协议。
序列化协议
基于文本编码的josn协议；二进制编码的protobuf、hession协议；针对java高性能高吞吐量的kryo和ftc协议。
既然有HTTP，为啥还要用RPC进行服务调用？
他们俩到底是哪里有差别？
五层协议体系：应用层，传输层，网络层，数据链路层，物理层。
应用层的任务是通过应用进程之间的交互来完成特定的网络应用。http就是应用层协议，使用TCP/IP通信协议来传递数据。
传输层的主要任务就是为两台主机之间的通信提供通用的数据传输服务。TCP就是传输层协议。
关键的差别就在于HTTP使用的TCP协议，RPC网络使用的自定义报文的TCP协议：
http1.1协议的TCP报文包含太多在传输过程中可能无用的信息。
使用自定的报文进行传输就会避免这个问题，极大减轻了数据传输的开销。在这点上RPC直接是提高了信息交换效率。除此之外，RPC框架还提供了&amp;quot;服务自动注册与发现&amp;quot;、“智能负载均衡”，“可视化的服务治理和运维”，“运行期流量调度”等功能。
RPC框架的基本架构：
三者交互方式：
1、服务端启动后，会将他提供的服务列表发布到注册中心，客户端向注册中心订阅服务地址；
2、客户端会通过本地代理模块Proxy调用服务端，Proxy模块负责将方法。参数等数据转化为网络字节流；
3、客户端从服务列表选取其中一个服务地址（通过负载均衡算法），并将数据通过网络发送给服务端；
4、服务端收到数据后进行解码，得到请求信息；
5、服务端根据解码后的请求信息调用对应的服务，然后将调用结果返回给客户端。
从上面这张图中，可以看见 RPC 框架一般有这些组件：服务治理(注册发现)、负载均衡、容错、序列化/反序列化、编解码、网络传输、线程池、动态代理等角色，当然有的RPC框架还会有连接池、日志、安全等角色。
stub是一个存根，
client stub ：存放服务端的地址消息，再将客户端的请求打包成网络消息，然后通过网络远程发送给服务方。
server stub：接受客户端发送过来的消息，消息解包并调用本地的方法。
交互过程：
1、客户端（client）以本地调用方式调用服务；
2、client stub接受到调用后负责将方法、参数封装成能够进行网络传输的消息体；
3、client stub将消息进行编码并发送到服务端；
4、server stub收到消息后进行解码；
5、server stub根据解码结果调用本地服务；
6、本地服务执行方法并将结果返回给server stub；
7、server stub将返回结果进行编码并发送给消费方；
8、client stub接受消息进行解码；
9、服务消费方（client）得到结果。</description>
    </item>
    
    <item>
      <title>对于RPC框架的初步理解</title>
      <link>https://lzy175.github.io/posts/%E5%AF%B9%E4%BA%8Erpc%E6%A1%86%E6%9E%B6%E7%9A%84%E5%88%9D%E6%AD%A5%E7%90%86%E8%A7%A3/</link>
      <pubDate>Mon, 28 Jun 2021 16:56:09 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E5%AF%B9%E4%BA%8Erpc%E6%A1%86%E6%9E%B6%E7%9A%84%E5%88%9D%E6%AD%A5%E7%90%86%E8%A7%A3/</guid>
      <description>rpc是指远程过程调用，关注的一般是远程方法调用，微服务会将一个项目服务分成几个规模较小的服务，把这些服务分别部署在不同的服务器中，来达到一种解耦合提高效率的目的，但是不同的服务之间一定会有交互，通过这种交互来完成系统的整体性，这种交互过程有时候就是一个服务得区调用另一个服务的方法，就是在一台服务器上，调用另一台服务器的某个方法，RPC就是这样一种框架，通过RPC可以在本地计算机上调用远程计算机上某个服务的方法。
RPC通常包括两类协议：1、传输协议和 序列化协议
传输协议：
著名的grpc，底层使用的就是http2协议；dubbo一类的是使用自定义报文的tcp协议。
序列化协议
基于文本编码的josn协议；二进制编码的protobuf、hession协议；针对java高性能高吞吐量的kryo和ftc协议。
既然有HTTP，为啥还要用RPC进行服务调用？
他们俩到底是哪里有差别？
五层协议体系：应用层，传输层，网络层，数据链路层，物理层。
应用层的任务是通过应用进程之间的交互来完成特定的网络应用。http就是应用层协议，使用TCP/IP通信协议来传递数据。
传输层的主要任务就是为两台主机之间的通信提供通用的数据传输服务。TCP就是传输层协议。
关键的差别就在于HTTP使用的TCP协议，RPC网络使用的自定义报文的TCP协议：
http1.1协议的TCP报文包含太多在传输过程中可能无用的信息，使用自定的报文进行传输就会避免这个问题，极大减轻了数据传输的开销。在这点上RPC直接是提高了信息交换效率。除此之外，RPC框架还提供了&amp;quot;服务自动注册与发现&amp;quot;、“智能负载均衡”，“可视化的服务治理和运维”，“运行期流量调度”等功能。
RPC框架的基本架构部件是三个，注册中心、客户端和服务端：
三者交互方式：
1、服务端启动后，会将他提供的服务列表发布到注册中心，客户端向注册中心订阅服务地址；
2、客户端会通过本地代理模块Proxy调用服务端，Proxy模块负责将方法。参数等数据转化为网络字节流；
3、客户端从服务列表选取其中一个服务地址（通过负载均衡算法），并将数据通过网络发送给服务端；
4、服务端收到数据后进行解码，得到请求信息；
5、服务端根据解码后的请求信息调用对应的服务，然后将调用结果返回给客户端。
交互过程：
1、客户端（client）以本地调用方式调用服务；
2、client stub接受到调用后负责将方法、参数封装成能够进行网络传输的消息体；
3、client stub将消息进行编码并发送到服务端；
4、server stub收到消息后进行解码；
5、server stub根据解码结果调用本地服务；
6、本地服务执行方法并将结果返回给server stub；
7、server stub将返回结果进行编码并发送给消费方；
8、client stub接受消息进行解码；
9、服务消费方（client）得到结果。</description>
    </item>
    
    <item>
      <title>IO与Netty实操问题</title>
      <link>https://lzy175.github.io/posts/netty/</link>
      <pubDate>Tue, 22 Jun 2021 17:42:29 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/netty/</guid>
      <description>IO与Netty实操问题 （分享以实际操作中遇到的问题为主，一些基础知识不会过多陈述）
(34条消息) 基于NIO的Socket通信(使用Java NIO的综合示例讲解)_Java新生代的博客-CSDN博客_java nio socket
两台计算机之间的通信，本质上可以理解为两台不同主机的进程之间的通信，简单的例子就是浏览器从服务器端接收网页、文件等。
根据OSI七层模型，计算机通信实际传输以二进制形式的数据在物理层进行，所以在通信中，需要通过序列化方式，将传输的对象转化为二进制形式流，这种在网络中以二进制形式传输的流就是IO流，对于应用端来说是输入流，对于服务端来说是输出流。
使用计算机的不同端口，可以编写一个IO通信的简单Demo。
客户端代码
package com.lzy.socketDemo; import com.sun.org.apache.xpath.internal.objects.XString; import java.io.*; import java.net.Inet4Address; import java.net.InetSocketAddress; import java.net.Socket; import java.net.UnknownHostException; /** * @ClassName: Client * @Description: socket客户端 * @author: lzy * @date: 2022/7/11 11:07 */ public class Client { public static void main(String[] args) throws IOException { Socket socket = new Socket(); // 设置超时时间 socket.setSoTimeout(8000); socket.connect(new InetSocketAddress(Inet4Address.getLocalHost(), 2000), 8000); System.out.println(&amp;#34;已发起服务器连接，并进入后续流程～&amp;#34;); System.out.println(&amp;#34;客户端信息：&amp;#34; + socket.getLocalAddress() + &amp;#34; P:&amp;#34; + socket.</description>
    </item>
    
    <item>
      <title>多路复用IO的底层实现及空轮询bug</title>
      <link>https://lzy175.github.io/posts/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8io%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8F%8A%E7%A9%BA%E8%BD%AE%E8%AF%A2bug/</link>
      <pubDate>Thu, 10 Jun 2021 10:24:48 +0800</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8io%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8F%8A%E7%A9%BA%E8%BD%AE%E8%AF%A2bug/</guid>
      <description>Netty中的NIO实现了reactor模式，通过将感兴趣的事件（比如刻度数据到达，新的套接字连接等等）注册到selector中，完成线程的异步通知。
这一过程的具体操作通过三个重要组件来完成，channel、buffer、selector。
**channel：**相当于IO操作的载体，可以近似理解为一个硬件设备，可以执行read/write，类似流，但流的读写单向，channel的读写双向。
**buffer：**buffer用于和通道进行交互，本质上是一块可以写入数据，也可以从中读取数据的内存。
**selector：**选择器是实现异步回调的关键，作用是检测各个通道，channel将关心的事件注册到selector上，selector能够知晓通道是否做好了数据准备，这样一个单线程就可以管理多个channel，从而管理多个网络连接。（这里思想在redis单线程中体现的极为明显）
底层实现 IO多路复用，从表面上可以简单理解为一种机制，一个进程可以监控多个文件描述符，一旦有某个描述符就绪，就能通知进程进行相应的读写操作。从宏观上，如果系统要对外提供一个进程可以监控多个连接方法的话，那么实现过程中需要考虑的问题有以下几条：
系统如何知道进程需要监控哪些连接和事件（fd）； 系统要使用什么方法对这些fd的状态进行监控； 系统监控到活跃事件之后，如何通知进程。 linux操作系统中，select、poll和epoll三种系统调用都可以解决以上三个问题，进而实现IO的多路复用。
select select监控连接的流程如下：
再调用select之前，系统需要知道需要监控哪些fd可读、可写、异常状态，这些事件分别存放在三个fd_set的数组中； 调用select时，系统要把fd_set从用户空间拷贝到内核空间（发生一次空间切换），内核空间拿到后，采用轮询的方式遍历fd_set数组，一个个扫描对应的事件是否准备就绪； 扫描到有对应事件发生后，内核会将把那些没有发生的事件的句柄清除，然后将fd_set发送给应用进程（又发生一次空间切换）。 引用进程拿到这个返回的fd_set之后，就知道哪些已经是准备就绪的事件了，对对应的事件发起数据读取或者写入的操作。 缺点：
每调用一下select，就要把三个fd_set数组从用户空间拷贝到内核空间，返回的时候还要再拷贝回来，当数组数据量很大的时候，消耗会很大； 内核需要将fd_set数组逐个遍历，检查哪些事件是准备就绪的，很耗时； fd_set数组有长度限制，32位系统是1024，64位系统是2048，也就是说select最多监控1024个连接。 poll poll主要就是再select的基础上作了两点改进：
事件集合不在使用数组，而是使用链表，没有了长度限制； 保存在链表里的，需要监控的fd信息采用了poll_fd的文件格式，select每一次调用都要重新注册感兴趣的事件和连接，poll不需要，pollfd保存了需要监控的事件集合，同时也保存了一个返回激活事件的fd事件集合。重新发送请求时不需要再次设置感兴趣的事件。 epoll epoll目前是实现多路复用IO的主流系统调用，epoll采用一组方法调用来对事件进行监控。大致流程如下：
epoll_create方法，向内核申请一个fd文件描述符作为内核事件监听表（B+树结构），这个描述符用来保存应用进程需要监控哪些fd和对应进程的事件； epoll_ctl方法，向事件监听表添加或者移除对应的fd和事件类型； epoll_wait方法，给需要监控的fd绑定回调事件，内核向事件表的fd绑定一个回调函数callback当监控的fd活跃时，会调用callback函数把事件加入到一个活跃事件队列里面，epoll_wait返回的时候，会将活跃时间队列里面的fd和事件类型返回给应用进程。 总的来说，epoll事先就在内核空间创建了一个事件监听表，后续操作只要向表内注册和删除感兴趣事件就行，因为本来就在内核空间，避免了两个空间的来回复制；并且给每个感兴趣的fd绑定了一个回调函数，当事件激活后会主动调用回调函数，将fd加入到活跃事件队列，避免了遍历操作。
jdk的epoll空轮询bug 使用IO复用，Linux下一般默认就是epoll，Java NIO在Linux下默认也是epoll机制，但是JDK中epoll的实现却是有漏洞的，其中最有名的java nio epoll bug就是即使是关注的select轮询事件返回数量为0，NIO照样不断的从select本应该阻塞的Selector.select()/Selector.select(timeout)中wake up出来，导致CPU 100%问题。
空轮询的伪代码：
// 轮询处理 while (true) { if (socket.isOpen()) { //在注册的键中选择已准备就绪的事件（这里可能会出现空轮询bug） selector.select(); //已选择键集 Set&amp;lt;SelectionKey&amp;gt; keys = selector.selectedKeys(); Iterator&amp;lt;SelectionKey&amp;gt; iterator = keys.iterator(); //处理准备就绪的事件 while (iterator.hasNext()) { /** 相关功能代码 */ } } } 在上述代码中，在调用selector.select()时，如果没有对应事件发生，线程应该阻塞在这，但是实际情况并不会，线程继续执行，selector.select()返回numKeys是0，所以下面本应该对key值进行遍历的事件处理根本执行不了，又回到最上面的while(true)循环，循环往复，不断的轮询，直到linux系统出现100%的CPU情况，其它执行任务干不了活，最终导致程序崩溃。有意思的是，这个bug的产生原因到现在还在不断甩锅中，linux方面说是jdk的问题，jdk方面说是linux的epoll的问题。</description>
    </item>
    
    <item>
      <title>三种时间复杂度为logn的排序算法</title>
      <link>https://lzy175.github.io/posts/%E4%B8%89%E7%A7%8D%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E4%B8%BAlogn%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lzy175.github.io/posts/%E4%B8%89%E7%A7%8D%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E4%B8%BAlogn%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</guid>
      <description>/** * @ClassName: SortInterface * @Description: 排序方法接口，所有排序方法必须实现这一接口 * @author: lzy * @date: 2020/12/12 9:08 */ public interface SortInterface { void sort(int[] nums); } 归并排序，这三个排序算法中唯一一个稳定的：
/** * @ClassName: MergeSort * @Description: 归并排序 * @author: lzy * @date: 2020/12/12 9:55 */ public class MergeSort implements SortInterface{ @Override public void sort(int[] nums) { Merge(nums, 0 , nums.length-1); } public void Merge(int[] nums , int left , int right){ if(left &amp;gt;= right){ return; } int index = (left + right)/2; Merge(nums , left , index); Merge(nums, index+1, right); MergeNums(nums , left , index , right); } public void MergeNums(int[] nums , int left , int index , int right){ int[] tmp = new int[right - left + 1]; int i = left; int j = index+1; int k = 0; while(i &amp;lt;= index &amp;amp;&amp;amp; j &amp;lt;= right){ if(nums[i] &amp;gt; nums[j]){ tmp[k++] = nums[j++]; }else { tmp[k++] = nums[i++]; } } while(i &amp;lt;= index){ tmp[k++] = nums[i++]; } while(j &amp;lt;= right){ tmp[k++] = nums[j++]; } //将tmp复制到nums中 for(int l = left ; l &amp;lt;= right ; l++){ nums[l] = tmp[l-left]; } } } 快排：</description>
    </item>
    
  </channel>
</rss>
